For this homework, I think the first probelm is a little bit difficult for me. So I pay lots of time on this problem. It requires us to implement two mapreduce job. Thefirst one is really easy, which is similar as the wordCount program we have finished. But for the second job, we should first compute the topN in mapper phase, and thencompute the global topN in the reducer phase. At first glance, I think it's not a big problem. But when I write and implement the second job. I meet some problems.First, I read the data in the mapper phase. and want to directly output (sumOfRatings,MovieTitle). But there are some mistakes when I read file at mapper phase. So I change the strategy: read file in reducer phase. This time I can get the correct answer, but  until now I still have no idea why the first try fails. I think it's logistially correct. The first problem is also the most interested problem, since it's really useful in daily life. And I think I can use it to solve some problems in real life. Additionally, the pair word_co-occurrence might also be useful, but the strips type might be better.
