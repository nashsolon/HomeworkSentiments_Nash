This homework provided helpful insight on how the MapReduce job runs, by giving me a chance to think about possible improvements, roles of different nodes, what the RecordReader is, and how Reduce Tasks outputs files into HDFS. Furthermore, I had a chance to compare the tradeoffs when dealing with data skew, which is a new concept learned from this homework. Finally, I could review the MapReduce processes and YARN daemons and their respective roles either on Master Node or Worker Node. Data locality optimization was an interesting concept for it was a bit ironic in a way that we are trying to schedule as much tasks locally(while we are learning virtual machine), and it indeed broadened my scope in job scheduling and execution.